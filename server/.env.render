# Render Deployment Configuration

# Set Render flag to true to activate Render-specific logic
RENDER=true

# Set Ollama host to false to disable Ollama and use fallback immediately
# Set to a valid URL if you have a hosted Ollama service
OLLAMA_HOST=false

# Set model to use for Ollama (if available)
OLLAMA_MODEL=llama3.2

# Increase timeout for production environment
OLLAMA_CONNECT_TIMEOUT=15000

# Fallback Services - Add your API keys here
# Uncomment and add API keys if you have them
# OPENAI_API_KEY=your-api-key-here
# GEMINI_API_KEY=your-api-key-here

# Set NODE_ENV for production
NODE_ENV=production

# TensorFlow Learning Configuration
EMBEDDING_DIM=384
LEARNING_RATE=0.001
MODELS_DIR=./models/ollama-tf
ENABLE_TENSORFLOW_LEARNING=true

# Connection timeout settings (in milliseconds)
DB_CONNECT_TIMEOUT=5000
API_TIMEOUT=30000

# Server Configuration
PORT=10000  # Render may assign a different port - will be set by Render's PORT environment variable 